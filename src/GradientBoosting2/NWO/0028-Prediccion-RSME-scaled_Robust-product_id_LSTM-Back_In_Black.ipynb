{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import labolibrary as labo\n",
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler,PowerTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DATOS_DIR = '~/buckets/b1/datasets/'\n",
    "DATOS_DIR = '../data/'      \n",
    "\n",
    "scalers = {}\n",
    "# Function to center, scale, and return a series\n",
    "def scale_group(group):\n",
    "    scaler = RobustScaler(with_centering=False)\n",
    "    #scaler = PowerTransformer()\n",
    "    scaled_values = scaler.fit_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    scalers[group.name] = scaler  # Store the scaler for this group\n",
    "    return pd.Series(scaled_values, index=group.index, name=group.name)\n",
    "\n",
    "# Function to inverse transform (de-scale) and decenter, and return a series\n",
    "def inverse_scale_group(group):\n",
    "    group_name = group.name\n",
    "    scaler = scalers[group_name]\n",
    "    inversed_centered_values = scaler.inverse_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    original_values = inversed_centered_values\n",
    "    return pd.Series(original_values, index=group.index, name=group_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer datos\n",
    "#df_final = pd.read_parquet(DATOS_DIR+'FE_dataset-CARLA.parquet') \n",
    "#import dask.dataframe as dd\n",
    "df_final = pd.read_parquet(DATOS_DIR+'FE_10_dataset.parquet') \n",
    "#df_final = df_final.compute()\n",
    "\n",
    "df_final.columns = df_final.columns.str.replace(' ', '_').str.replace(r'[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ESTO ES UN HACK PORQUE ESTA MAL ARMADA LA FUNCIÓN DE ESCALADO Y SOLO GUARDA LOS DATOS DE LA ÜLTIMA APLICACIÓN\n",
    "\n",
    "with open(DATOS_DIR + '/scalers.pkl', 'rb') as file:\n",
    "    scalers = pickle.load(file)\n",
    "\n",
    "#df_test = df_final[(df_final['product_id'] == 21276) & (df_final['customer_id'] == 10029)][['product_id','tn', 'weight']]\n",
    "#df_test['tn'] = df_test.groupby('product_id')['tn'].transform(inverse_scale_group)\n",
    "\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Filtrar datos\n",
    "df_true = df_final.loc['2019-12-01':'2020-01-01']\n",
    "df_final = df_final.loc['2018-01-01':'2019-11-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df_true[['product_id','customer_id','tn']]\n",
    "df_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_true['tn'] = df_true.groupby(['product_id','customer_id'])['tn'].transform(inverse_scale_group)\n",
    "#pred_true = df_true.groupby(['product_id'])['tn'].sum()\n",
    "#pred_true.to_csv(DATOS_DIR+'/pred/TRUE-NOVEMBER.csv', index=True,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final[df_final['product_id'] == 20402 & df_final['customer_id'] == 10479][['product_id','tn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Filtro test\n",
    "#\n",
    "#\n",
    "# df_final = df_final[df_final['product_id'] < 20013]\n",
    "#df_final = df_final[df_final['product_id'] == 20072]\n",
    "\n",
    "weight= df_final[['weight','product_id','customer_id']]\n",
    "#df_final.drop(columns=['weight'], inplace=True)\n",
    "#filtered_weight = weight[weight['weight'] != 0]\n",
    "#weight_mean = filtered_weight.groupby('product_id')['weight'].mean().to_dict()\n",
    "#weight['weight'] = weight['product_id'].map(weight_mean)\n",
    "\n",
    "weight = weight.groupby(['product_id','customer_id'])['weight'].mean()\n",
    "weight = weight.reset_index()\n",
    "df_final = df_final.drop(columns=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr Modelo\n",
    "params={\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'Regression',\n",
    "        'metric':'rmse',\n",
    "        'verbose': -1,\n",
    "        #'n_jobs': -1,\n",
    "        'seed': 113,\n",
    "        #'learning_rate': 0.2,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        #'colsample_bytree': 0.85,\n",
    "        #'colsample_bynode': 0.85,\n",
    "        'min_data_per_leaf': 25,\n",
    "        'num_leaves': 200,\n",
    "        #'lambda_l1': 0.5,\n",
    "        #'lambda_l2': 0.5\n",
    "}\n",
    "\n",
    "df_final['tn_2'].fillna(0, inplace=True)\n",
    "predictions_all = pd.DataFrame(columns=['tn'])\n",
    "products = df_final['product_id'].unique()\n",
    "tot = len(products)\n",
    "nro = 0\n",
    "\n",
    "for producto in products:\n",
    "    print(f'Fitting and predicting for product_id: {producto}')\n",
    "    # Filtrar los datos del producto\n",
    "    df_producto = df_final[df_final['product_id'] == producto]\n",
    "    \n",
    "    product_weights = pd.merge(df_producto.reset_index(), weight, on=['product_id', 'customer_id'], how='left')\n",
    "    product_weights.set_index('periodo', inplace=True)\n",
    "    weight_p = product_weights['weight']\n",
    "    \n",
    "    df_producto['tn_2'] = df_producto['tn_2'].fillna(0)\n",
    "  \n",
    "    #############################################################################  \n",
    "    #### Agrupar y escalar\n",
    "   \n",
    "    model, average_metric = labo.train_lightgbm_model(df_producto,params,metric='rmse',\n",
    "                                                      weights=weight_p)\n",
    "    print(\"Overall rmse metric: \", average_metric)\n",
    "    # Predict values for the entire dataset using the trained models\n",
    "    # Prepare last data points for prediction\n",
    "    last_data_points = df_producto[df_producto.index == df_producto.index.max()].copy()\n",
    "    last_data_points.drop(columns=['tn_2'], inplace=True)\n",
    "    # Predict the next month's value using the trained model\n",
    "    predictions = labo.predict_next_month_customer(model, last_data_points)\n",
    "    preds = predictions.groupby(['product_id'])['tn_2'].transform(inverse_scale_group)\n",
    "    predictions['tn'] = preds\n",
    "    predictions.drop(columns=['tn_2'], inplace=True)\n",
    "    predictions = predictions.reset_index()\n",
    "    predictions =  predictions.groupby('product_id')['tn'].sum()\n",
    "    predictions.columns = ['product_id', 'tn']\n",
    "    predictions_all = pd.concat([predictions_all, predictions])\n",
    "    print(predictions_all[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_all['tn']=predictions_all['tn'].astype('float32')\n",
    "predictions_all.index.names = ['product_id']\n",
    "predictions_all.to_csv(DATOS_DIR+'/pred/0028-prediccion-RSME_scaled_Robust-product_id_LSTM-Back_In_Black.csv', index=True,header=True)\n",
    "print(\"Overall custom metric: \", average_metric)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
