{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import labolibrary as labo\n",
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATOS_DIR = '~/buckets/b1/datasets/'\n",
    "#DATOS_DIR = '../data/'      \n",
    "\n",
    "scalers = {}\n",
    "# Function to center, scale, and return a series\n",
    "def scale_group(group):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_values = scaler.fit_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    scalers[group.name] = scaler  # Store the scaler for this group\n",
    "    return pd.Series(scaled_values, index=group.index, name=group.name)\n",
    "\n",
    "# Function to inverse transform (de-scale) and decenter, and return a series\n",
    "def inverse_scale_group(group):\n",
    "    group_name = group.name\n",
    "    scaler = scalers[group_name]\n",
    "    inversed_centered_values = scaler.inverse_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    original_values = inversed_centered_values\n",
    "    return pd.Series(original_values, index=group.index, name=group_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer datos\n",
    "#df_final = pd.read_parquet(DATOS_DIR+'FE_dataset-CARLA.parquet') \n",
    "df_final = pd.read_parquet(DATOS_DIR+'/FE_03_dataset.parquet') \n",
    "df_final.columns = df_final.columns.str.replace(' ', '_').str.replace(r'[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight = df_final.groupby(['product_id', df_final.index])['weight'].transform('mean')\n",
    "\n",
    "df_final.groupby('product_id')['weight'].transform(scale_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Filtrar datos\n",
    "df_true = df_final.loc['2019-12-01':'2020-01-01']\n",
    "df_final = df_final.loc['2018-01-01':'2019-11-01']\n",
    "\n",
    "\n",
    "#Filtro de no compradores\n",
    "#Step 1: Ensure the index is a datetime type\n",
    "df_final.index = df_final.index.to_timestamp()\n",
    "# Step 2: Determine the last date and calculate the date 3 months prior\n",
    "ls_date  = df_final.index.max()\n",
    "three_months_prior = ls_date - pd.DateOffset(months=3)\n",
    "\n",
    "# Step 3: Filter the dataframe to include onl+y rows within the last 3 months\n",
    "last_3_months_df = df_final[df_final.index >= three_months_prior]\n",
    "\n",
    "# Step 4: Identify the unique client_id that have purchased within this period\n",
    "active_clients = last_3_months_df['customer_id'].unique()\n",
    "\n",
    "# Step 5: Filter the original dataframe to include only these client_id\n",
    "df_final = df_final[df_final['customer_id'].isin(active_clients)]\n",
    "\n",
    "df_final.index = pd.PeriodIndex(df_final.index, freq='M')\n",
    "\n",
    "\n",
    "#Filtro test\n",
    "df_final = df_final[df_final['product_id'] < 20013]\n",
    "\n",
    "weight= df_final[['weight','product_id']]\n",
    "df_final.drop(columns=['weight'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr Modelo\n",
    "params={\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'Regression',\n",
    "        'metric':'rmse',\n",
    "        'verbose': -1,\n",
    "        #'n_jobs': -1,\n",
    "        'seed': 10000079,\n",
    "        #'learning_rate': 0.2,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        #'colsample_bytree': 0.85,\n",
    "        #'colsample_bynode': 0.85,\n",
    "        #'min_data_per_leaf': 25,\n",
    "        #'num_leaves': 200,\n",
    "        #'lambda_l1': 0.5,\n",
    "        #'lambda_l2': 0.5\n",
    "}\n",
    "\n",
    "predictions_all = pd.DataFrame(columns=['tn'])\n",
    "products = df_final['product_id'].unique()\n",
    "tot = len(products)\n",
    "nro = 0\n",
    "for producto in products:\n",
    "    print(f'Fitting and predicting for product_id: {producto}')\n",
    "    # Filtrar los datos del producto\n",
    "    df_producto = df_final[df_final['product_id'] == producto]\n",
    "    weight_p= weight[weight['product_id'] == producto]\n",
    "    # Prepare data for LSTM on tn_2 only\n",
    "    X = df_producto[['tn_2']].values.astype('float32')\n",
    "    y = df_producto['tn_2'].values.astype('float32')\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    #######################################################    \n",
    "    # Define LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    # Train LSTM model\n",
    "    model.fit(X, y, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Extract features from LSTM\n",
    "    features = model.predict(X)\n",
    "\n",
    "    # Prepare data for LightGBM\n",
    "    # Convert LSTM features to DataFrame\n",
    "    features_df = pd.DataFrame(features, index=df_producto.index, columns=[f'lstm_feature_{i}' for i in range(features.shape[1])])\n",
    "    df_producto = pd.concat([df_producto, features_df], axis=1)\n",
    "    df_producto['tn_2'] = y\n",
    "    \n",
    "    #############################################################################  \n",
    "    #### Agrupar y escalar\n",
    "   \n",
    "    model, average_metric = labo.train_lightgbm_model(df_producto,params,metric='rmse',\n",
    "                                                      weights=weight_p['weight'])\n",
    "    print(\"Overall rmse metric: \", average_metric)\n",
    "    # Predict values for the entire dataset using the trained models\n",
    "    # Prepare last data points for prediction\n",
    "    last_data_points = df_producto[df_producto.index == df_producto.index.max()].copy()\n",
    "    last_data_points.drop(columns=['tn_2'], inplace=True)\n",
    "    # Predict the next month's value using the trained model\n",
    "    predictions = labo.predict_next_month(model, last_data_points)\n",
    "    preds = predictions.groupby('product_id')['tn_2'].transform(inverse_scale_group)\n",
    "    predictions['tn'] = preds\n",
    "    predictions.drop(columns=['tn_2'], inplace=True)\n",
    "    predictions = predictions.reset_index()\n",
    "    predictions =  predictions.groupby('product_id')['tn'].sum()\n",
    "    predictions.columns = ['product_id', 'tn']\n",
    "    predictions_all = pd.concat([predictions_all, predictions])\n",
    "    print(predictions_all[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weight_p['weight'])\n",
    "len(df_producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_all['tn']=predictions_all['tn'].astype('float32')\n",
    "predictions_all.index.names = ['product_id']\n",
    "predictions_all.to_csv(DATOS_DIR+'/pred/0019-prediccion-rmse_scaled_CORRECT2-product_id_LSTM-No_Buyer_weights.csv', index=True,header=True)\n",
    "print(\"Overall custom metric: \", average_metric)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
