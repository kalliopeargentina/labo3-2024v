{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastdtw as dtw\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATOS_DIR = '~/buckets/b1/datasets/'\n",
    "DATOS_DIR = '../data/'\n",
    "\n",
    "# Leer datos\n",
    "df_orig = pd.read_parquet(DATOS_DIR+'FE_07_dataset.parquet') \n",
    "df_orig.columns = df_orig.columns.str.replace(' ', '_').str.replace(r'[^A-Za-z0-9_]', '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_orig.reset_index()\n",
    "df = df[df['product_id'] < 20002]\n",
    "\n",
    "df['periodo'] = pd.to_datetime(df['periodo'].astype(str))\n",
    "df.drop(columns=['descripcion'], inplace=True)\n",
    "df['periodo'] = pd.to_datetime(df['periodo'].astype(str))\n",
    "df = pl.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the selected columns are valid\n",
    "selected_columns = ['periodo', 'customer_id', 'product_id', 'tn', 'tn_2', 'diff_tn_tn2']  \n",
    "\n",
    "\n",
    "# Select and sort the dataframe\n",
    "df = df.select(selected_columns).sort(['product_id', 'customer_id', 'periodo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing products:   0%|          | 0/1 [00:00<?, ?it/s]d:\\Dropbox\\Python\\LaboIII\\labo3-2024v\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Processing products: 100%|██████████| 1/1 [01:49<00:00, 109.17s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def create_lstm_features(customer_data):\n",
    "    if customer_data.shape[0] < 2:\n",
    "        return [], []\n",
    "\n",
    "    # Prepare the data for LSTM\n",
    "    series = customer_data.drop(['tn_2', 'periodo']).to_numpy().astype(np.float32)\n",
    "    target = customer_data['tn_2'].to_numpy().astype(np.float32)\n",
    "    periodos = customer_data['periodo'].to_numpy()\n",
    "    \n",
    "    n_features = series.shape[1]\n",
    "    \n",
    "    X, y, time_indexes = [], [], []\n",
    "    for i in range(len(series) - 1):\n",
    "        seq_x, seq_y = series[i:i + 1], target[i + 1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        time_indexes.append(periodos[i + 1])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))\n",
    "    \n",
    "    # Define LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X, y, epochs=10,batch_size=32, verbose=1)\n",
    "    \n",
    "    # Generate LSTM features\n",
    "    lstm_features = model.predict(X, verbose=0)\n",
    "    \n",
    "    return lstm_features, time_indexes\n",
    "\n",
    "def process_customer(product_id, customer_id):\n",
    "    df_p = df.filter((pl.col('product_id') == product_id) & (pl.col('customer_id') == customer_id))\n",
    "    customer_data_count = df_p.shape[0]\n",
    "    if customer_data_count < 2:\n",
    "        return []\n",
    "    lstm_features, time_indexes = create_lstm_features(df_p)\n",
    "    return [(product_id, customer_id, feature[0], time_index) for feature, time_index in zip(lstm_features, time_indexes)]\n",
    "\n",
    "# Apply the function to all customers\n",
    "customer_ids = df.select(pl.col('customer_id')).unique().to_series().to_list()\n",
    "product_ids = df.select(pl.col('product_id')).unique().to_series().to_list()\n",
    "lstm_features_list = []\n",
    "for proid in tqdm(product_ids, desc=\"Processing products\"):\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_customer)(proid, cid) for cid in customer_ids\n",
    "    )\n",
    "    for result in results:\n",
    "        if result:\n",
    "            lstm_features_list.extend(result)\n",
    "\n",
    "# Convert list to DataFrame\n",
    "lstm_features_df = pl.DataFrame({\n",
    "    'product_id': [item[0] for item in lstm_features_list],\n",
    "    'customer_id': [item[1] for item in lstm_features_list],\n",
    "    'lstm_feature': [item[2] for item in lstm_features_list],\n",
    "    'periodo': [item[3] for item in lstm_features_list]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "datatypes of join keys don't match - `product_id`: i32 on left does not match `product_id`: null on right",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Join the new columns to the original dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_features_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduct_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustomer_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperiodo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dropbox\\Python\\LaboIII\\labo3-2024v\\.venv\\lib\\site-packages\\polars\\dataframe\\frame.py:6787\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, left_on, right_on, suffix, validate, join_nulls, coalesce)\u001b[0m\n\u001b[0;32m   6783\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected `other` join table to be a DataFrame, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m   6786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 6787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6794\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_nulls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin_nulls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoalesce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   6800\u001b[0m )\n",
      "File \u001b[1;32md:\\Dropbox\\Python\\LaboIII\\labo3-2024v\\.venv\\lib\\site-packages\\polars\\lazyframe\\frame.py:1942\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, background, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# Only for testing purposes atm.\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mComputeError\u001b[0m: datatypes of join keys don't match - `product_id`: i32 on left does not match `product_id`: null on right"
     ]
    }
   ],
   "source": [
    "\n",
    "# Join the new columns to the original dataframe\n",
    "df = df.join(lstm_features_df, on=['product_id', 'customer_id', 'periodo'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()\n",
    "df.set_index('periodo', inplace=True)\n",
    "df.index = df.index.to_period('M')\n",
    "\n",
    "df.to_parquet(DATOS_DIR+'/FE_10_dataset-LSTM.parquet', engine='pyarrow')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
