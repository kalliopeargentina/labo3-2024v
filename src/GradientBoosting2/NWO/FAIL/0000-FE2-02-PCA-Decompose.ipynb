{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATOS_DIR = '~/buckets/b1/datasets/'\n",
    "DATOS_DIR = '../data/'\n",
    "\n",
    "# Leer datos\n",
    "df = pd.read_parquet(DATOS_DIR+'FE_02_dataset.parquet') \n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace(r'[^A-Za-z0-9_]', '', regex=True)\n",
    "\n",
    "### Filtrar datos\n",
    "df = df.loc['2018-01-01':'2019-11-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot dataframe\n",
    "pivot_df = df.pivot_table(index='periodo', columns=['product_id', 'customer_id'], values='tn', fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857c501f315f4d73b530bc414029178a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating features:   0%|          | 0/237102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize list to hold feature dataframes\n",
    "feature_list = []\n",
    "\n",
    "# Minimum required observations for seasonal decomposition\n",
    "min_observations = 24\n",
    "\n",
    "# Calculate features for each product-customer time series with progress bar\n",
    "for col in tqdm(pivot_df.columns, desc=\"Calculating features\"):\n",
    "    series = pivot_df[col]\n",
    "    \n",
    "    # Check if the series has enough observations\n",
    "    if series.count() < min_observations:\n",
    "        # Interpolate to fill missing values\n",
    "        series = series.interpolate(method='linear')\n",
    "    \n",
    "    mean_val = series.mean()\n",
    "    std_val = series.std()\n",
    "    \n",
    "    # Try to perform seasonal decomposition\n",
    "    try:\n",
    "        decomposition = seasonal_decompose(series, model='additive', period=12)\n",
    "        trend_val = decomposition.trend.mean()\n",
    "        seasonality_val = decomposition.seasonal.mean()\n",
    "    except ValueError:\n",
    "        # If seasonal decomposition fails, set trend and seasonality to NaN\n",
    "        trend_val = np.nan\n",
    "        seasonality_val = np.nan\n",
    "    \n",
    "    # Create a temporary dataframe for the features\n",
    "    temp_df = pd.DataFrame({\n",
    "        'product_id': [col[0]],\n",
    "        'customer_id': [col[1]],\n",
    "        'mean': [mean_val],\n",
    "        'std': [std_val],\n",
    "        'trend': [trend_val],\n",
    "        'seasonality': [seasonality_val]\n",
    "    })\n",
    "    \n",
    "    # Append the temporary dataframe to the feature list\n",
    "    feature_list.append(temp_df)\n",
    "\n",
    "# Concatenate all the temporary dataframes into a single dataframe\n",
    "features = pd.concat(feature_list, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with 0 or another appropriate value\n",
    "features.fillna(0, inplace=True)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features[['mean', 'std', 'trend', 'seasonality']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "pca_features = pca.fit_transform(scaled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add PCA features to the dataframe\n",
    "features[['pca1', 'pca2', 'pca3', 'pca4']] = pca_features\n",
    "\n",
    "# Clustering (example with KMeans)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(pca_features)\n",
    "\n",
    "# Add cluster information to the dataframe\n",
    "features['cluster'] = clusters\n",
    "\n",
    "# Merge the features back to the original dataframe\n",
    "# First, reset the index of the original dataframe\n",
    "df_reset = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the original dataframe with the features dataframe\n",
    "result_df = df_reset.merge(features, on=['product_id', 'customer_id'])\n",
    "\n",
    "\n",
    "result_df.set_index('periodo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_parquet(DATOS_DIR+'/FE_dataset-PCA-Decompose.parquet', engine='pyarrow')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
