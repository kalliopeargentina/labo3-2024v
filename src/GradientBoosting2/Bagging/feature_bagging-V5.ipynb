{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d162f9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e936de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from feature_baggingV2 import FeatureBaggingWithHyperparamTuning\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab055280",
   "metadata": {},
   "source": [
    "### Función para escalar/desescalar y métrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3fda6f0-64b9-407c-a972-5495038181b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para escalar y devolver una serie\n",
    "def minmax_scale_group(group):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_values = scaler.fit_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    scalers[group.name] = scaler  # Almacenar el escalador para este grupo\n",
    "    return pd.Series(scaled_values, index=group.index)\n",
    "\n",
    "# Función para desescalar y devolver una serie\n",
    "def inverse_minmax_scale_group(group):\n",
    "    scaler = scalers[group.name]\n",
    "    inversed_values = scaler.inverse_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    return pd.Series(inversed_values, index=group.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df25936b-3c56-4ff0-be2c-aa2b2da9b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la métrica personalizada\n",
    "def multinacional_metric(y_true, y_pred):\n",
    "    return abs(sum(y_true - y_pred)) / sum(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d682256",
   "metadata": {},
   "source": [
    "### Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1bb9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS_DIR = 'C:\\\\Users\\\\ccarl\\\\Downloads\\\\Labo3\\\\'\n",
    "df_sell_in = pd.read_csv(DATOS_DIR+'sell-in.txt', sep='\\t')\n",
    "df_predecir = pd.read_csv(DATOS_DIR+'productos_a_predecir.txt', sep='\\t')\n",
    "df_tb_stocks = pd.read_csv(DATOS_DIR+'tb_stocks.txt', sep='\\t')\n",
    "df_tb_productos = pd.read_csv(DATOS_DIR+'tb_productos_descripcion.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0ff2c",
   "metadata": {},
   "source": [
    "Si quiero predecir algun mes en especifico y filtrar los productos con más de 3 meses de venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccf4fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sell_in = df_sell_in[df_sell_in['periodo']<201808]\n",
    "#df_sell_in['tn_2'] = np.where(df_sell_in['periodo'].isin([201805, 201804]), np.nan, df_sell_in['tn_2']) \n",
    "#df_sell_in = df_sell_in[df_sell_in['periodo']<201806]\n",
    "#sales_counts = df_sell_in.groupby('product_id')['periodo'].count() # Contar el número de meses de ventas por product_id\n",
    "#products_with_more_than_3_months = sales_counts[sales_counts > 3].index # Filtrar los productos con más de 3 meses de ventas\n",
    "#df_sell_in = df_sell_in[df_sell_in['product_id'].isin(products_with_more_than_3_months)] # Filtrar el DataFrame original para incluir solo estos productos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81dfad9",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a9543cd-acdd-40e7-b8e6-89e3fa904f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb_stocks['periodo'] = pd.to_datetime(df_tb_stocks['periodo'], format='%Y%m')\n",
    "df_tb_stocks['periodo'] = df_tb_stocks['periodo'] - pd.DateOffset(months=1) #mes diferente en stock\n",
    "\n",
    "\n",
    "df_tb_stocks['product_id'] = df_tb_stocks['product_id'].astype(int)\n",
    "df_tb_stocks['stock_final'] = df_tb_stocks['stock_final'].astype(float)\n",
    "df_tb_productos['product_id'] = df_tb_productos['product_id'].astype(int)\n",
    "df_tb_productos['sku_size'] = df_tb_productos['sku_size'].astype(int)\n",
    "df_sell_in['periodo'] = pd.to_datetime(df_sell_in['periodo'], format='%Y%m')\n",
    "df_sell_in['product_id'] = df_sell_in['product_id'].astype(int)\n",
    "df_sell_in['customer_id'] = df_sell_in['customer_id'].astype(int)\n",
    "df_sell_in['cust_request_qty'] = df_sell_in['cust_request_qty'].astype(int)\n",
    "df_sell_in['cust_request_tn'] = df_sell_in['cust_request_tn'].astype(float)\n",
    "df_sell_in['tn'] = df_sell_in['tn'].astype(float)\n",
    "df_sell_in['plan_precios_cuidados'] = df_sell_in['plan_precios_cuidados'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a06313",
   "metadata": {},
   "source": [
    "### Consolidar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "976db310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sell_in['tn_2'] = df_sell_in['tn'].shift(-2) #OBTENGO TN 2 MESES ADELANTE (CLASE FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f111859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tb_productos to sell_in on product_id\n",
    "df_sell_in_merged = pd.merge(df_sell_in, df_tb_productos, on='product_id', how='left')\n",
    "# Join tb_stocks to sell_in_merged on both product_id and periodo\n",
    "df_final = pd.merge(df_sell_in_merged, df_tb_stocks, on=['product_id', 'periodo'], how='left')\n",
    "\n",
    "#Convertir 'periodo' a formato de fecha y Calcular el trimestre desde 'periodo'\n",
    "df_final['fecha'] = pd.to_datetime(df_final['periodo'], format='%Y%m')\n",
    "df_final[\"trimestre\"] = df_final.periodo.dt.quarter\n",
    "\n",
    "#Establecer 'fecha' como índice y convertir a período mensual\n",
    "df_final.set_index('fecha', inplace=True)\n",
    "df_final.index = df_final.index.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d63c5f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_2</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>trimestre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2945818 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "fecha                                                                \n",
       "2017-01 2017-01-01        10234       20524                  False   \n",
       "2017-01 2017-01-01        10032       20524                  False   \n",
       "2017-01 2017-01-01        10217       20524                  False   \n",
       "2017-01 2017-01-01        10125       20524                  False   \n",
       "2017-01 2017-01-01        10012       20524                  False   \n",
       "...            ...          ...         ...                    ...   \n",
       "2019-12 2019-12-01        10105       20853                  False   \n",
       "2019-12 2019-12-01        10092       20853                  False   \n",
       "2019-12 2019-12-01        10006       20853                  False   \n",
       "2019-12 2019-12-01        10018       20853                  False   \n",
       "2019-12 2019-12-01        10020       20853                  False   \n",
       "\n",
       "         cust_request_qty  cust_request_tn       tn     tn_2 cat1     cat2  \\\n",
       "fecha                                                                        \n",
       "2017-01                 2          0.05300  0.05300  0.03028   HC  VAJILLA   \n",
       "2017-01                 1          0.13628  0.13628  0.02271   HC  VAJILLA   \n",
       "2017-01                 1          0.03028  0.03028  1.54452   HC  VAJILLA   \n",
       "2017-01                 1          0.02271  0.02271  0.01514   HC  VAJILLA   \n",
       "2017-01                11          1.54452  1.54452  0.10600   HC  VAJILLA   \n",
       "...                   ...              ...      ...      ...  ...      ...   \n",
       "2019-12                 1          0.02230  0.02230  0.02898   PC  CABELLO   \n",
       "2019-12                 1          0.00669  0.00669  0.01561   PC  CABELLO   \n",
       "2019-12                 7          0.02898  0.02898  0.01561   PC  CABELLO   \n",
       "2019-12                 4          0.01561  0.01561      NaN   PC  CABELLO   \n",
       "2019-12                 2          0.01561  0.01561      NaN   PC  CABELLO   \n",
       "\n",
       "                 cat3      brand  sku_size    descripcion  stock_final  \\\n",
       "fecha                                                                    \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "...               ...        ...       ...            ...          ...   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "\n",
       "         trimestre  \n",
       "fecha               \n",
       "2017-01          1  \n",
       "2017-01          1  \n",
       "2017-01          1  \n",
       "2017-01          1  \n",
       "2017-01          1  \n",
       "...            ...  \n",
       "2019-12          4  \n",
       "2019-12          4  \n",
       "2019-12          4  \n",
       "2019-12          4  \n",
       "2019-12          4  \n",
       "\n",
       "[2945818 rows x 16 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8711a",
   "metadata": {},
   "source": [
    "### Clase de LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b1251be-71fb-4a68-9ac1-93ea5e68df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['diff_tn_tn2'] =  df_final['tn_2'] - df_final['tn'] #NUEVA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13f86583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_2</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>stock_final</th>\n",
       "      <th>trimestre</th>\n",
       "      <th>diff_tn_tn2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.02272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.11357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.51424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.00757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>HC</td>\n",
       "      <td>VAJILLA</td>\n",
       "      <td>Cristalino</td>\n",
       "      <td>Importado</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Abrillantador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.43852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.01337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>Shampoo Bebe</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Sabor 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2945818 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "fecha                                                                \n",
       "2017-01 2017-01-01        10234       20524                  False   \n",
       "2017-01 2017-01-01        10032       20524                  False   \n",
       "2017-01 2017-01-01        10217       20524                  False   \n",
       "2017-01 2017-01-01        10125       20524                  False   \n",
       "2017-01 2017-01-01        10012       20524                  False   \n",
       "...            ...          ...         ...                    ...   \n",
       "2019-12 2019-12-01        10105       20853                  False   \n",
       "2019-12 2019-12-01        10092       20853                  False   \n",
       "2019-12 2019-12-01        10006       20853                  False   \n",
       "2019-12 2019-12-01        10018       20853                  False   \n",
       "2019-12 2019-12-01        10020       20853                  False   \n",
       "\n",
       "         cust_request_qty  cust_request_tn       tn     tn_2 cat1     cat2  \\\n",
       "fecha                                                                        \n",
       "2017-01                 2          0.05300  0.05300  0.03028   HC  VAJILLA   \n",
       "2017-01                 1          0.13628  0.13628  0.02271   HC  VAJILLA   \n",
       "2017-01                 1          0.03028  0.03028  1.54452   HC  VAJILLA   \n",
       "2017-01                 1          0.02271  0.02271  0.01514   HC  VAJILLA   \n",
       "2017-01                11          1.54452  1.54452  0.10600   HC  VAJILLA   \n",
       "...                   ...              ...      ...      ...  ...      ...   \n",
       "2019-12                 1          0.02230  0.02230  0.02898   PC  CABELLO   \n",
       "2019-12                 1          0.00669  0.00669  0.01561   PC  CABELLO   \n",
       "2019-12                 7          0.02898  0.02898  0.01561   PC  CABELLO   \n",
       "2019-12                 4          0.01561  0.01561      NaN   PC  CABELLO   \n",
       "2019-12                 2          0.01561  0.01561      NaN   PC  CABELLO   \n",
       "\n",
       "                 cat3      brand  sku_size    descripcion  stock_final  \\\n",
       "fecha                                                                    \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "2017-01    Cristalino  Importado     500.0  Abrillantador          NaN   \n",
       "...               ...        ...       ...            ...          ...   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "2019-12  Shampoo Bebe      NIVEA     200.0        Sabor 1          NaN   \n",
       "\n",
       "         trimestre  diff_tn_tn2  \n",
       "fecha                            \n",
       "2017-01          1     -0.02272  \n",
       "2017-01          1     -0.11357  \n",
       "2017-01          1      1.51424  \n",
       "2017-01          1     -0.00757  \n",
       "2017-01          1     -1.43852  \n",
       "...            ...          ...  \n",
       "2019-12          4      0.00668  \n",
       "2019-12          4      0.00892  \n",
       "2019-12          4     -0.01337  \n",
       "2019-12          4          NaN  \n",
       "2019-12          4          NaN  \n",
       "\n",
       "[2945818 rows x 17 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78673c",
   "metadata": {},
   "source": [
    "## FE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c480ae",
   "metadata": {},
   "source": [
    "### Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a51bb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\648479522.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "# Create lag variables for 'cust_request_qty', 'cust_request_tn', and 'tn'\n",
    "n_lags = 36\n",
    "for lag in range(1, n_lags + 1):\n",
    "    df_final[f'cust_request_qty_lag_{lag}'] = df_final['cust_request_qty'].shift(lag)\n",
    "    df_final[f'cust_request_tn_lag_{lag}'] = df_final['cust_request_tn'].shift(lag)\n",
    "    df_final[f'stock_final_lag_{lag}'] = df_final['stock_final'].shift(lag)\n",
    "    df_final[f'tn_lag_{lag}'] = df_final['tn'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ace50b01-3709-4959-826a-4c6a5457510c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\260571944.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+2}'] = (\n"
     ]
    }
   ],
   "source": [
    "#DELTA DE LAGS 2 ANTERIORES\n",
    "\n",
    "for lag in range(1, n_lags-1):\n",
    "    df_final[f'delta_cust_request_tn_{lag}_{lag+2}'] = (\n",
    "        df_final[f'cust_request_tn_lag_{lag+2}'] - df_final[f'cust_request_tn_lag_{lag}']\n",
    "    )\n",
    "    df_final[f'delta_stock_final_{lag}_{lag+2}'] = (\n",
    "        df_final[f'stock_final_lag_{lag+2}'] - df_final[f'stock_final_lag_{lag}']\n",
    "    )\n",
    "    df_final[f'delta_tn_{lag}_{lag+2}'] = (\n",
    "        df_final[f'tn_lag_{lag+2}'] - df_final[f'tn_lag_{lag}']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a0344e6-f9fa-44e8-afbb-078714138dd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\1785296116.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'delta_tn_{lag}_{lag+1}'] = (\n"
     ]
    }
   ],
   "source": [
    "#DELTA DE LAGS 1 ANTERIOR\n",
    "\n",
    "for lag in range(1, n_lags):\n",
    "    df_final[f'delta_cust_request_tn_{lag}_{lag+1}'] = (\n",
    "        df_final[f'cust_request_tn_lag_{lag+1}'] - df_final[f'cust_request_tn_lag_{lag}']\n",
    "    )\n",
    "    df_final[f'delta_stock_final_{lag}_{lag+1}'] = (\n",
    "        df_final[f'stock_final_lag_{lag+1}'] - df_final[f'stock_final_lag_{lag}']\n",
    "    )\n",
    "    df_final[f'delta_tn_{lag}_{lag+1}'] = (\n",
    "        df_final[f'tn_lag_{lag+1}'] - df_final[f'tn_lag_{lag}']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac8c6059-98cd-41a5-a091-00a9b002d748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_stock_final_{lag}'] = (\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\2974401302.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'ratio_tn_{lag}'] = (\n"
     ]
    }
   ],
   "source": [
    "#Mes actual / (lag 2 + lag 3) \n",
    "\n",
    "# Calcular el ratio del valor actual con respecto a la suma de los dos lags anteriores\n",
    "for lag in range(3, n_lags + 1):\n",
    "    df_final[f'ratio_cust_request_tn_{lag}'] = (\n",
    "        df_final[f'cust_request_tn_lag_{lag}'] / (\n",
    "            df_final[f'cust_request_tn_lag_{lag-1}'] + df_final[f'cust_request_tn_lag_{lag-2}']\n",
    "        )\n",
    "    )\n",
    "    df_final[f'ratio_stock_final_{lag}'] = (\n",
    "        df_final[f'stock_final_lag_{lag}'] / (\n",
    "            df_final[f'stock_final_lag_{lag-1}'] + df_final[f'stock_final_lag_{lag-2}']\n",
    "        )\n",
    "    )\n",
    "    df_final[f'ratio_tn_{lag}'] = (\n",
    "        df_final[f'tn_lag_{lag}'] / (\n",
    "            df_final[f'tn_lag_{lag-1}'] + df_final[f'tn_lag_{lag-2}']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58601c78-bf4b-4487-b213-5232aee182a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3586226101.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d80ab",
   "metadata": {},
   "source": [
    "### Medias Móviles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f741da5-1bfb-4141-8cf0-f934b4f6de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3749147370.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n"
     ]
    }
   ],
   "source": [
    "#MEDIAS MOVILES\n",
    "rolling_windows = [3, 6, 9, 12, 24, 36]\n",
    "\n",
    "# Agrupamos por 'product_id' y calculamos las medias móviles para 'tn'\n",
    "for window in rolling_windows:\n",
    "    df_final[f'rolling_mean_tn_{window}'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(window, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbacef",
   "metadata": {},
   "source": [
    "### FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bcaaf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3544365912.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['year'] = df_final['periodo'].dt.year\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3544365912.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['month'] = df_final['periodo'].dt.month\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3544365912.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['quarter'] = df_final.periodo.dt.quarter\n"
     ]
    }
   ],
   "source": [
    "# Datetime features\n",
    "df_final['year'] = df_final['periodo'].dt.year\n",
    "df_final['month'] = df_final['periodo'].dt.month\n",
    "df_final['quarter'] = df_final.periodo.dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "077969b2-c2e3-45f4-b0f9-e5938833f13f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'max_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).max())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'min_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).min())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_max_{i}m'] = np.where(df_final['tn'] == df_final[f'max_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_min_{i}m'] = np.where(df_final['tn'] == df_final[f'min_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'max_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).max())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'min_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).min())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_max_{i}m'] = np.where(df_final['tn'] == df_final[f'max_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_min_{i}m'] = np.where(df_final['tn'] == df_final[f'min_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'max_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).max())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'min_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).min())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_max_{i}m'] = np.where(df_final['tn'] == df_final[f'max_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_min_{i}m'] = np.where(df_final['tn'] == df_final[f'min_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'max_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).max())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'min_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).min())\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_max_{i}m'] = np.where(df_final['tn'] == df_final[f'max_{i}m'], 1, 0)\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3137070357.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f'dummy_min_{i}m'] = np.where(df_final['tn'] == df_final[f'min_{i}m'], 1, 0)\n"
     ]
    }
   ],
   "source": [
    "#Variables Dummies si es el max o el min de cierta cantidad de meses\n",
    "months = [3, 6, 9, 12]\n",
    "\n",
    "# Agrupamos por 'product_id' y calculamos las medias móviles para 'tn'\n",
    "for i in months:\n",
    "    df_final[f'max_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).max())\n",
    "    df_final[f'min_{i}m'] = df_final.groupby('product_id')['tn'].transform(lambda x: x.rolling(i, min_periods=1).min())\n",
    "    # Crear las dummies\n",
    "    df_final[f'dummy_max_{i}m'] = np.where(df_final['tn'] == df_final[f'max_{i}m'], 1, 0)\n",
    "    df_final[f'dummy_min_{i}m'] = np.where(df_final['tn'] == df_final[f'min_{i}m'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "216de0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3111183930.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['tn_trimestre'] = df_final.groupby(['trimestre', 'product_id'])['tn'].transform('sum')\n",
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\3111183930.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['tn_trimestre_customer'] = df_final.groupby(['trimestre','customer_id', 'product_id'])['tn'].transform('sum')\n"
     ]
    }
   ],
   "source": [
    "#Calcular ventas por trimestre\n",
    "df_final['tn_trimestre'] = df_final.groupby(['trimestre', 'product_id'])['tn'].transform('sum')\n",
    "#Calcular ventas por trimestre por cliente\n",
    "df_final['tn_trimestre_customer'] = df_final.groupby(['trimestre','customer_id', 'product_id'])['tn'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d8a0126-8b20-4739-b2ae-b62a335f8d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccarl\\AppData\\Local\\Temp\\ipykernel_11516\\4104376824.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final['tn_product_id'] = df_final.groupby(['periodo', 'product_id'])['tn'].transform('sum')\n"
     ]
    }
   ],
   "source": [
    "df_final['tn_product_id'] = df_final.groupby(['periodo', 'product_id'])['tn'].transform('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f8e56",
   "metadata": {},
   "source": [
    "### FE variables externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5796bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo exportado\n",
    "df_exported = pd.read_excel('23variables_externas.xlsx')\n",
    "\n",
    "# Asegúrate de que las columnas de fecha estén en el formato datetime\n",
    "df_exported['fecha'] = pd.to_datetime(df_exported['fecha'])\n",
    "\n",
    "# Unir los DataFrames por la columna de fecha\n",
    "df_merged = pd.merge(df_final, df_exported, on='fecha', how='left')\n",
    "\n",
    "# Mostrar el DataFrame unido\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31c4774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tn_2</th>\n",
       "      <th>cat1</th>\n",
       "      <th>...</th>\n",
       "      <th>min_9m</th>\n",
       "      <th>dummy_max_9m</th>\n",
       "      <th>dummy_min_9m</th>\n",
       "      <th>max_12m</th>\n",
       "      <th>min_12m</th>\n",
       "      <th>dummy_max_12m</th>\n",
       "      <th>dummy_min_12m</th>\n",
       "      <th>tn_trimestre</th>\n",
       "      <th>tn_trimestre_customer</th>\n",
       "      <th>tn_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>HC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64.00631</td>\n",
       "      <td>0.12871</td>\n",
       "      <td>6.48085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>HC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00631</td>\n",
       "      <td>1.36281</td>\n",
       "      <td>6.48085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>HC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.00631</td>\n",
       "      <td>0.09842</td>\n",
       "      <td>6.48085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.01514</td>\n",
       "      <td>HC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.00631</td>\n",
       "      <td>0.03785</td>\n",
       "      <td>6.48085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>HC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00631</td>\n",
       "      <td>7.38191</td>\n",
       "      <td>6.48085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945813</th>\n",
       "      <td>2019-12</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>PC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62426</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.55436</td>\n",
       "      <td>0.10479</td>\n",
       "      <td>2.89842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945814</th>\n",
       "      <td>2019-12</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62426</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.55436</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>2.89842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945815</th>\n",
       "      <td>2019-12</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>PC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62426</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.55436</td>\n",
       "      <td>0.66662</td>\n",
       "      <td>2.89842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945816</th>\n",
       "      <td>2019-12</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62426</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.55436</td>\n",
       "      <td>0.31213</td>\n",
       "      <td>2.89842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945817</th>\n",
       "      <td>2019-12</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62426</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.55436</td>\n",
       "      <td>0.09587</td>\n",
       "      <td>2.89842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2945818 rows × 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           fecha    periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "0        2017-01 2017-01-01        10234       20524                  False   \n",
       "1        2017-01 2017-01-01        10032       20524                  False   \n",
       "2        2017-01 2017-01-01        10217       20524                  False   \n",
       "3        2017-01 2017-01-01        10125       20524                  False   \n",
       "4        2017-01 2017-01-01        10012       20524                  False   \n",
       "...          ...        ...          ...         ...                    ...   \n",
       "2945813  2019-12 2019-12-01        10105       20853                  False   \n",
       "2945814  2019-12 2019-12-01        10092       20853                  False   \n",
       "2945815  2019-12 2019-12-01        10006       20853                  False   \n",
       "2945816  2019-12 2019-12-01        10018       20853                  False   \n",
       "2945817  2019-12 2019-12-01        10020       20853                  False   \n",
       "\n",
       "         cust_request_qty  cust_request_tn       tn     tn_2 cat1  ...  \\\n",
       "0                       2          0.05300  0.05300  0.03028   HC  ...   \n",
       "1                       1          0.13628  0.13628  0.02271   HC  ...   \n",
       "2                       1          0.03028  0.03028  1.54452   HC  ...   \n",
       "3                       1          0.02271  0.02271  0.01514   HC  ...   \n",
       "4                      11          1.54452  1.54452  0.10600   HC  ...   \n",
       "...                   ...              ...      ...      ...  ...  ...   \n",
       "2945813                 1          0.02230  0.02230  0.02898   PC  ...   \n",
       "2945814                 1          0.00669  0.00669  0.01561   PC  ...   \n",
       "2945815                 7          0.02898  0.02898  0.01561   PC  ...   \n",
       "2945816                 4          0.01561  0.01561      NaN   PC  ...   \n",
       "2945817                 2          0.01561  0.01561      NaN   PC  ...   \n",
       "\n",
       "          min_9m dummy_max_9m dummy_min_9m  max_12m  min_12m  dummy_max_12m  \\\n",
       "0        0.05300            1            1  0.05300  0.05300              1   \n",
       "1        0.05300            1            0  0.13628  0.05300              1   \n",
       "2        0.03028            0            1  0.13628  0.03028              0   \n",
       "3        0.02271            0            1  0.13628  0.02271              0   \n",
       "4        0.02271            1            0  1.54452  0.02271              1   \n",
       "...          ...          ...          ...      ...      ...            ...   \n",
       "2945813  0.00446            0            0  0.62426  0.00446              0   \n",
       "2945814  0.00446            0            0  0.62426  0.00446              0   \n",
       "2945815  0.00446            0            0  0.62426  0.00446              0   \n",
       "2945816  0.00446            0            0  0.62426  0.00446              0   \n",
       "2945817  0.00446            0            0  0.62426  0.00446              0   \n",
       "\n",
       "         dummy_min_12m  tn_trimestre  tn_trimestre_customer  tn_product_id  \n",
       "0                    1      64.00631                0.12871        6.48085  \n",
       "1                    0      64.00631                1.36281        6.48085  \n",
       "2                    1      64.00631                0.09842        6.48085  \n",
       "3                    1      64.00631                0.03785        6.48085  \n",
       "4                    0      64.00631                7.38191        6.48085  \n",
       "...                ...           ...                    ...            ...  \n",
       "2945813              0      18.55436                0.10479        2.89842  \n",
       "2945814              0      18.55436                0.01561        2.89842  \n",
       "2945815              0      18.55436                0.66662        2.89842  \n",
       "2945816              0      18.55436                0.31213        2.89842  \n",
       "2945817              0      18.55436                0.09587        2.89842  \n",
       "\n",
       "[2945818 rows x 499 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba335349-b121-4b0e-91b2-24965083ab36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2930202222.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    asda df_final['plan_precios_cuidados'] =df_final['plan_precios_cuidados'].astype(bool)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_final['plan_precios_cuidados'] =df_final['plan_precios_cuidados'].astype(bool)\n",
    "#df_final['dias_fin_trimestre'] = df_final['dias_fin_trimestre'].dt.days.astype(int) #TARDA!\n",
    "df_final = df_final.drop(columns=['fecha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725f8a6",
   "metadata": {},
   "source": [
    "## Inicio Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75dca6-f165-42dc-8d2a-b2d6484d7cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Cambiar las variables categoricas y hacer one-hot encoding\n",
    "\n",
    "# df_final[\"cat1\"] = df_final[\"cat1\"].astype(\"category\")\n",
    "# df_final[\"cat2\"] = df_final[\"cat2\"].astype(\"category\")\n",
    "# df_final[\"cat3\"] = df_final[\"cat3\"].astype(\"category\")\n",
    "# df_final[\"brand\"] = df_final[\"brand\"].astype(\"category\")\n",
    "# df_final[\"descripcion\"] = df_final[\"descripcion\"].astype(\"category\")\n",
    "\n",
    "# # Encode categorical variables explicitly. One-hot encoding\n",
    "# cat1_dummies = pd.get_dummies(df_final['cat1'], prefix='cat1', drop_first=True)\n",
    "# cat2_dummies = pd.get_dummies(df_final['cat2'], prefix='cat2', drop_first=True)\n",
    "# cat3_dummies = pd.get_dummies(df_final['cat3'], prefix='cat3', drop_first=True)\n",
    "# brand_dummies = pd.get_dummies(df_final['brand'], prefix='brand', drop_first=True)\n",
    "# descripcion_dummies = pd.get_dummies(df_final['descripcion'], prefix='descripcion', drop_first=True)\n",
    "\n",
    "# # Concatenate the dummy variables to the DataFrame and drop the original categorical columns\n",
    "# df_final= pd.concat([df_final, cat1_dummies, cat2_dummies, cat3_dummies, brand_dummies, descripcion_dummies], axis=1)\n",
    "# df_final.drop(columns=['cat1', 'cat2', 'cat3', 'brand'], inplace=True)\n",
    "\n",
    "# df_final.set_index('periodo', inplace=True)\n",
    "# df_final.index = df_final.index.to_period('M')\n",
    "# df_final.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "df_final['tn'] = df_final.groupby('product_id')['tn'].transform(minmax_scale_group) #escalado\n",
    "df_final['tn_2'] = df_final.groupby('product_id')['tn_2'].transform(minmax_scale_group) #escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4a749-0106-4611-818c-4f6145d0063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'tweedie',\n",
    "        'tweedie_variance_power': 1.1,\n",
    "        'metric':'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.2,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 1, \n",
    "        'colsample_bytree': 0.85,\n",
    "        'colsample_bynode': 0.85,\n",
    "        #'min_data_per_leaf': 25,\n",
    "        #'num_leaves': 200,\n",
    "        'lambda_l1': 0.5,\n",
    "        'lambda_l2': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776971d-2720-44e0-af32-a24c81562ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94963104-c7e8-476e-993b-e2ccb4f70431",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '1'                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED  \n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'tn_2'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = datetime.datetime(year=2019,month=12,day=1) - pd.DateOffset(months=6)           # End day of our train set\n",
    "PRED = '2019-12-01'\n",
    "P_HORIZON   = pd.DateOffset(months=1)                  # Prediction horizon\n",
    "USE_AUX     = False               # Use or not pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7a447-6885-4d86-8bde-693a92689738",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTS_IDS = df_predecir['product_id'].unique()\n",
    "DESCRIPCION_TYPES = df_tb_productos['descripcion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc1a4f-363a-4c90-a537-4d07b9d8f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d33ac-6a06-443c-8ffd-8659c95e203d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: cat1: object, cat2: object, cat3: object, brand: object, descripcion: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(train_data_filtered\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[TARGET]), \n\u001b[0;32m     31\u001b[0m                              label\u001b[38;5;241m=\u001b[39mtrain_data_filtered[TARGET])\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_data.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data.bin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m     valid_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(valid_data_filtered\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[TARGET]), \n\u001b[0;32m     36\u001b[0m                        label\u001b[38;5;241m=\u001b[39mvalid_data_filtered[TARGET])\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:2566\u001b[0m, in \u001b[0;36mDataset.save_binary\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m   2547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_binary\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2548\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save Dataset to a binary file.\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m \n\u001b[0;32m   2550\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;124;03m        Returns self.\u001b[39;00m\n\u001b[0;32m   2564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2565\u001b[0m     _safe_call(_LIB\u001b[38;5;241m.\u001b[39mLGBM_DatasetSaveBinary(\n\u001b[1;32m-> 2566\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   2567\u001b[0m         _c_str(\u001b[38;5;28mstr\u001b[39m(filename))))\n\u001b[0;32m   2568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:2462\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2455\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2456\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor,\n\u001b[0;32m   2457\u001b[0m                 data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   2458\u001b[0m                 used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2459\u001b[0m             )\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2461\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2462\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2463\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2464\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2465\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2466\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:2022\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 2022\u001b[0m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2029\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n\u001b[0;32m   2030\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:825\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    821\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    822\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 825\u001b[0m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    826\u001b[0m     feature_name,\n\u001b[0;32m    827\u001b[0m     categorical_feature,\n\u001b[0;32m    828\u001b[0m     pandas_categorical\n\u001b[0;32m    829\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:771\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[1;34m(data, target_dtype)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pandas_to_numpy\u001b[39m(\n\u001b[0;32m    768\u001b[0m     data: pd_DataFrame,\n\u001b[0;32m    769\u001b[0m     target_dtype: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.typing.DTypeLike\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    770\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 771\u001b[0m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto_numpy(dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ccarl\\miniforge3\\envs\\myenv\\lib\\site-packages\\lightgbm\\basic.py:763\u001b[0m, in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[1;34m(pandas_dtypes_series)\u001b[0m\n\u001b[0;32m    757\u001b[0m bad_pandas_dtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype\u001b[38;5;241m.\u001b[39mtype)\n\u001b[0;32m    761\u001b[0m ]\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    764\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: cat1: object, cat2: object, cat3: object, brand: object, descripcion: object"
     ]
    }
   ],
   "source": [
    "for descripcion_type in DESCRIPCION_TYPES:\n",
    "    \n",
    "    grid_df = data[data['descripcion']==descripcion_type]\n",
    "    train_mask = grid_df['periodo']<=END_TRAIN\n",
    "    valid_mask = train_mask&(grid_df['periodo']>(END_TRAIN-P_HORIZON))\n",
    "    preds_mask = grid_df['periodo']==(PRED)\n",
    "\n",
    "    train_data_filtered = grid_df[train_mask].drop(columns=['periodo'])\n",
    "    valid_data_filtered = grid_df[valid_mask].drop(columns=['periodo'])\n",
    "    preds_data_filtered = grid_df[preds_mask].drop(columns=['periodo'])\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    \n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    if train_data_filtered.empty:\n",
    "        # Si el conjunto de entrenamiento está vacío, llenar y_pred con ceros\n",
    "        preds_data_filtered['prediction'] = 0\n",
    "\n",
    "    else:\n",
    "        train_data = lgb.Dataset(train_data_filtered.drop(columns=[TARGET]), \n",
    "                                 label=train_data_filtered[TARGET])\n",
    "        train_data.save_binary('train_data.bin')\n",
    "        train_data = lgb.Dataset('train_data.bin')\n",
    "        \n",
    "        valid_data = lgb.Dataset(valid_data_filtered.drop(columns=[TARGET]), \n",
    "                           label=valid_data_filtered[TARGET])\n",
    "        \n",
    "        if valid_data_filtered.empty:\n",
    "            estimator = lgb.train(lgb_params,\n",
    "                            train_data,\n",
    "                            num_boost_round=3600)\n",
    "\n",
    "        else:\n",
    "            estimator = lgb.train(lgb_params,\n",
    "                            train_data,\n",
    "                            num_boost_round=3600,\n",
    "                            valid_sets=[train_data, valid_data],\n",
    "                            callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
    "        \n",
    "    \n",
    "        # Realizar predicciones\n",
    "        y_pred = estimator.predict(preds_data_filtered.drop(columns=[TARGET]), num_iteration=estimator.best_iteration)\n",
    "        \n",
    "        # Agregar las predicciones al DataFrame\n",
    "        preds_data_filtered['prediction'] = y_pred\n",
    "        #preds_data_filtered['product_id'] = product_id\n",
    "\n",
    "        # Save model - it's not real '.bin' but a pickle file\n",
    "        # estimator = lgb.Booster(model_file='model.txt')\n",
    "        # can only predict with the best iteration (or the saving iteration)\n",
    "        # pickle.dump gives us more flexibility\n",
    "        # like estimator.predict(TEST, num_iteration=100)\n",
    "        # num_iteration - number of iteration want to predict with, \n",
    "        # NULL or <= 0 means use best iteration\n",
    "            # \"Keep\" models features for predictions\n",
    "        model_name = 'lgb_model_'+descripcion_type +'_v'+(VERSION)+'.bin'\n",
    "        pickle.dump(estimator, open(model_name, 'wb'))\n",
    "    \n",
    "        # Remove temporary files and objects \n",
    "        # to free some hdd space and ram memory\n",
    "        !rm train_data.bin\n",
    "        del train_data, valid_data, estimator\n",
    "        gc.collect()\n",
    "\n",
    "    preds_data_filtered['tn_2'] = preds_data_filtered.groupby('product_id')['tn_2'].transform(inverse_minmax_scale_group)\n",
    "    preds_data_filtered = preds_data_filtered.groupby(['product_id'])['tn_2'].agg('sum')\n",
    "    preds_data_filtered = preds_data_filtered.reset_index()\n",
    "    preds_data_filtered = preds_data_filtered.rename(columns={'tn_2': 'tn'}) #PREDICCION TN DE 2 MESES ADELANTE\n",
    "\n",
    "    all_preds = pd.concat([all_preds, preds_data_filtered], axis=0)\n",
    "\n",
    "\n",
    "# Guardar todas las predicciones en un archivo CSV\n",
    "all_preds.to_csv('all_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82bb2c-56f6-418e-9531-f2d2158920c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_predecir2\n",
    "# #SI QUIERO COMPARAR CONTRA julio\n",
    "# df_sell_in_julio = pd.read_csv('data/sell-in.txt', sep='\\t')\n",
    "# df_sell_in_julio = df_sell_in_julio[df_sell_in_julio['periodo'] == 201807]\n",
    "\n",
    "# # Contar el número de meses de ventas por product_id\n",
    "# sales_counts_julio = df_sell_in_julio.groupby('product_id')['periodo'].count()\n",
    "# products_with_more_than_3_months_julio = sales_counts[sales_counts > 3].index\n",
    "# df_sell_in_julio = df_sell_in_julio[df_sell_in_julio['product_id'].isin(products_with_more_than_3_months_julio)]\n",
    "\n",
    "# valores_reales_julio = df_sell_in_julio\n",
    "# valores_reales_julio = valores_reales_julio.groupby(['product_id'])['tn'].agg('sum')\n",
    "\n",
    "# # Combinar predicciones y valores reales\n",
    "# resultados = data_predecir2.merge(valores_reales_julio, on='product_id')\n",
    "\n",
    "# productos = df_tb_productos.loc[:, ['product_id','cat1']]\n",
    "\n",
    "# resultados = resultados.merge(productos, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a1902-dbd4-47de-aa50-a4fcc8dcf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular la métrica\n",
    "#resultados = resultados[resultados['cat1']=='FOODS']\n",
    "#y_true = resultados['tn']\n",
    "#y_pred = resultados['pred']\n",
    "#metric_result = multinacional_metric(y_true, y_pred)\n",
    "#metric_result\n",
    "#df_predictions\n",
    "#resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
