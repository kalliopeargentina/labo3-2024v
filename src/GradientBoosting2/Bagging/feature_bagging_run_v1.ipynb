{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8babaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from feature_bagging import FeatureBaggingWithHyperparamTuning\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebcaa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_parquet('./FE_dataset-CARLA.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69512fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para escalar y devolver una serie\n",
    "def minmax_scale_group(group):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_values = scaler.fit_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    scalers[group.name] = scaler  # Almacenar el escalador para este grupo\n",
    "    return pd.Series(scaled_values, index=group.index)\n",
    "\n",
    "# Función para desescalar y devolver una serie\n",
    "def inverse_minmax_scale_group(group):\n",
    "    scaler = scalers[group.name]\n",
    "    inversed_values = scaler.inverse_transform(group.values.reshape(-1, 1)).flatten()\n",
    "    return pd.Series(inversed_values, index=group.index)\n",
    "\n",
    "# Definir la métrica personalizada\n",
    "def multinacional_metric(y_true, y_pred):\n",
    "    return abs(sum(y_true - y_pred)) / sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "217ff1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "df_final['tn'] = df_final.groupby('product_id')['tn'].transform(minmax_scale_group) #escalado\n",
    "df_final['tn_2'] = df_final.groupby('product_id')['tn_2'].transform(minmax_scale_group) #escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b0bbce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id              0\n",
      "product_id               0\n",
      "plan_precios_cuidados    0\n",
      "cust_request_qty         0\n",
      "cust_request_tn          0\n",
      "                        ..\n",
      "dummy_max_12m            0\n",
      "dummy_min_12m            0\n",
      "tn_product_id            0\n",
      "month                    0\n",
      "year                     0\n",
      "Length: 364, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14708\\918435596.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[numeric_columns] = data[numeric_columns].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "nan_count = df_final.isnull().sum()\n",
    "print(nan_count)\n",
    "data = df_final.loc['2018-01-01':'2020-12-01']\n",
    "#data = data[data['product_id'] == 20441] \n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "data[categorical_columns] = data[categorical_columns].fillna('Sin Datos')\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "data[numeric_columns] = data[numeric_columns].fillna(0)\n",
    "data = data.copy()\n",
    "\n",
    "#TEST\n",
    "#true =df_final.loc['2019-09-01':'2019-10-01']\n",
    "#true = true[true['product_id'] == 20441]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9df89dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 32\u001b[0m\n\u001b[0;32m     23\u001b[0m feature_bagging_model \u001b[38;5;241m=\u001b[39m FeatureBaggingWithHyperparamTuning(\n\u001b[0;32m     24\u001b[0m     X, y, n_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m     25\u001b[0m     feature_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000841\u001b[39m,\n\u001b[0;32m     29\u001b[0m     optimization_target\u001b[38;5;241m=\u001b[39mmultinacional_metric)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Fit the model with a single seed\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mfeature_bagging_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m single_seed_predictions \u001b[38;5;241m=\u001b[39m feature_bagging_model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Define multiple seeds\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#seeds = [10000019, 20000379, 30000841, 40001387, 50001863]\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Fit the model with multiple seeds and get combined predictions\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#combined_predictions = feature_bagging_model.fit_multiple_seeds(seeds)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Realizar el pronóstico para 2 meses adelante\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\Python\\labo3-2024v\\src\\GradientBoosting2\\Bagging\\feature_bagging.py:92\u001b[0m, in \u001b[0;36mFeatureBaggingWithHyperparamTuning.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_subsets\u001b[38;5;241m.\u001b[39mappend(feature_subset)\n\u001b[0;32m     87\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[0;32m     88\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlgb_cv,\n\u001b[0;32m     89\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_bounds,\n\u001b[0;32m     90\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m     91\u001b[0m )\n\u001b[1;32m---> 92\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\bayes_opt\\bayesian_optimization.py:284\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prime_subscriptions()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_START)\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prime_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m old_params_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m([param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m [acq, kappa, kappa_decay, kappa_decay_delay, xi]])\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_params_used \u001b[38;5;129;01mor\u001b[39;00m gp_params:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\bayes_opt\\bayesian_optimization.py:241\u001b[0m, in \u001b[0;36mBayesianOptimization._prime_queue\u001b[1;34m(self, init_points)\u001b[0m\n\u001b[0;32m    238\u001b[0m     init_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(init_points, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(init_points):\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\bayes_opt\\target_space.py:264\u001b[0m, in \u001b[0;36mTargetSpace.random_sample\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreates random points within the bounds of the space.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03marray([[ 55.33253689,   0.54488318]])\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim))\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, (lower, upper) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds):\n\u001b[0;32m    265\u001b[0m     data\u001b[38;5;241m.\u001b[39mT[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\u001b[38;5;241m.\u001b[39muniform(lower, upper, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "# Define parameter bounds for Bayesian optimization\n",
    "param_bounds = {\n",
    "    'num_leaves': (10, 20),\n",
    "    'learning_rate': (0.01, 0.1),\n",
    "    'n_estimators': (50, 100 ),\n",
    "    'min_child_samples': (5, 10),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'max_depth': (5, 10)\n",
    "}\n",
    "# Custom optimization target function\n",
    "def multinacional_metric(y_true, y_pred):\n",
    "     return abs(sum(y_true - y_pred)) / sum(y_true)\n",
    "\n",
    "\n",
    "# Filtrar los datos del producto\n",
    "X = data.drop(columns=['tn_2'])\n",
    "X = X.copy()\n",
    "y = data['tn_2']\n",
    "y= y.copy()\n",
    "# Create the feature bagging model\n",
    "feature_bagging_model = FeatureBaggingWithHyperparamTuning(\n",
    "    X, y, n_models=10, \n",
    "    feature_fraction=0.5, \n",
    "    sample_fraction=0.8, \n",
    "    param_bounds=param_bounds, \n",
    "    random_state=30000841,\n",
    "    optimization_target=multinacional_metric)\n",
    "\n",
    "# Fit the model with a single seed\n",
    "feature_bagging_model.fit()\n",
    "single_seed_predictions = feature_bagging_model.predict(X)\n",
    "\n",
    "# Define multiple seeds\n",
    "#seeds = [10000019, 20000379, 30000841, 40001387, 50001863]\n",
    "    # Fit the model with multiple seeds and get combined predictions\n",
    "#combined_predictions = feature_bagging_model.fit_multiple_seeds(seeds)\n",
    "\n",
    "# Realizar el pronóstico para 2 meses adelante\n",
    "forecast = feature_bagging_model.forecast(X, n_periods=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f44eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tn_2': 0.013036592164882756}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener la predicción del segundo mes\n",
    "second_month_prediction = forecast[0]  # .iloc[1] obtiene el segundo valor predicho\n",
    "\n",
    "# Almacenar el producto_id y la predicción en la lista\n",
    "predictions.append({'tn_2': second_month_prediction})\n",
    "print({'tn_2': second_month_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb631b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20032</td>\n",
       "      <td>590.333660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21153</td>\n",
       "      <td>0.589564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21159</td>\n",
       "      <td>0.513512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21168</td>\n",
       "      <td>0.488598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20286</td>\n",
       "      <td>49.778057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20442</td>\n",
       "      <td>31.269903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20491</td>\n",
       "      <td>15.661783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20548</td>\n",
       "      <td>20.247307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20620</td>\n",
       "      <td>15.088071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20623</td>\n",
       "      <td>26.421832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id          tn\n",
       "0       20032  590.333660\n",
       "1       21153    0.589564\n",
       "2       21159    0.513512\n",
       "3       21168    0.488598\n",
       "4       20286   49.778057\n",
       "5       20442   31.269903\n",
       "6       20491   15.661783\n",
       "7       20548   20.247307\n",
       "8       20620   15.088071\n",
       "9       20623   26.421832"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la lista a un DataFrame\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "df_predictions.to_csv('../data/predicciones.csv', index=False,header=True)\n",
    "df_predictions.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
